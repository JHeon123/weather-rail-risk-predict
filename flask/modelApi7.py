from flask import Flask, request, jsonify
import joblib
import numpy as np
import tensorflow as tf
import torch
import os

from tensorflow.keras.models import load_model
from model7.preprocess7 import preprocess_raw_input_v2

# env/Scripts/activate
# ------------ ë””ë²„ê·¸ ì„¤ì • ------------ #
DEBUG = os.getenv("DEBUG", "false").lower() == "true"

def debug_print(*args):
    if DEBUG:
        print(*args)

# ------------ Flask App ------------ #
app = Flask(__name__)

# ------------ ì»¤ìŠ¤í…€ ì†ì‹¤ í•¨ìˆ˜ ------------ #
@tf.keras.utils.register_keras_serializable()
def loss_fn(y_true, y_pred):
    y_true = tf.cast(y_true, tf.int32)
    y_true_onehot = tf.one_hot(y_true, depth=tf.shape(y_pred)[-1])
    cross_entropy = -y_true_onehot * tf.math.log(tf.clip_by_value(y_pred, 1e-9, 1.0))
    weight = 0.25 * tf.pow(1 - y_pred, 2.0)
    loss = weight * cross_entropy
    return tf.reduce_sum(loss, axis=1)

# ------------ ë¦¬ì†ŒìŠ¤ ë¡œë”© ------------ #
debug_print("ğŸ”„ ì „ì²˜ë¦¬ ë¦¬ì†ŒìŠ¤ ë¡œë”© ì¤‘...")
feature_order = joblib.load('model7/feature_order.pkl')
label_encoders = joblib.load('model7/label_encoders.pkl')
imputer = joblib.load('model7/imputer.pkl')
scaler = joblib.load('model7/scaler.pkl')
class_names = joblib.load('model7/class_names.pkl')
damage_lookup = joblib.load('model7/damage_lookup.pkl')
debug_print("âœ… ì „ì²˜ë¦¬ ë¦¬ì†ŒìŠ¤ ë¡œë”© ì™„ë£Œ")

# ------------ ìœ„í—˜ë„ ê´€ë ¨ ------------ #
class_risk_weights = {
    'ì°¨ëŸ‰/ê¸°íƒ€ì„¤ë¹„ I/F': 3,
    'ê¸°íƒ€': 2,
    'ì„ ë¡œë°êµ¬ì¡°ë¬¼': 2,
    'í™˜ê²½ìš”ì¸': 2,
    'ì°¨ëŸ‰/ì„ ë¡œ ë° êµ¬ì¡°ë¬¼ I/F': 1,
    'ì°¨ëŸ‰/í†µì‹  I/F': 1,
    'ì°¨ëŸ‰/ì‹ í˜¸ I/F': 1,
    'ì •ë³´í†µì‹ ì„¤ë¹„': 1
}

def damage_to_risk(damage):
    if damage == 0:
        return 1
    elif damage <= 0.2:
        return 2
    elif damage <= 1.0:
        return 3
    elif damage <= 5.0:
        return 4
    else:
        return 5

# ------------ ëª¨ë¸ ë¡œë”© ------------ #
debug_print("ğŸ”„ Keras ëª¨ë¸ ë¡œë”© ì¤‘...")
model = load_model('model7/railway_safety_model.h5', custom_objects={"loss_fn": loss_fn})
debug_print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

# ------------ ì˜ˆì¸¡ API ------------ #
@app.route('/predict_batch_v3', methods=['POST'])
def predict_batch_v3():
    try:
        input_list = request.get_json()
        debug_print(f"ğŸ“¥ [ì…ë ¥ ìˆ˜ì‹ ] ìš”ì²­ ìƒ˜í”Œ ìˆ˜: {len(input_list)}")

        # [1] ë°°ì¹˜ ì „ì²˜ë¦¬
        input_tensors = []
        for idx, input_dict in enumerate(input_list):
            debug_print(f"\nğŸ§¾ [ìƒ˜í”Œ {idx}] ì›ë³¸ ì…ë ¥ ë°ì´í„°:")
            debug_print(input_dict)

            input_tensor = preprocess_raw_input_v2(
                raw_input=input_dict,
                feature_order=feature_order,
                label_encoders=label_encoders,
                imputer=imputer,
                scaler=scaler
            )
            input_tensor = input_tensor.squeeze(0)  # ğŸ‘ˆ ì—¬ê¸° ì¶”ê°€!
            input_tensors.append(input_tensor)

        # [2] ë°°ì¹˜ ëª¨ë¸ ì¶”ë¡ 
        batch_tensor = torch.stack(input_tensors)
        debug_print(f"ğŸ“¡ ë°°ì¹˜ ëª¨ë¸ ì¶”ë¡  ì‹œì‘... (ë°°ì¹˜ í¬ê¸°: {batch_tensor.shape[0]})")
        preds = model.predict(batch_tensor.numpy())
        debug_print(f"ğŸ“ˆ ì „ì²´ softmax ì¶œë ¥ ì˜ˆì‹œ [0]: {preds[0].tolist()}")

        # [3] ê²°ê³¼ ìƒì„±
        results = []
        for idx, (input_dict, pred_row) in enumerate(zip(input_list, preds)):
            pred_class_idx = np.argmax(pred_row)
            pred_class_name = class_names[pred_class_idx]
            
            #â›”ï¸ ì˜ˆì¸¡ ê²°ê³¼ê°€ "ê·¼ë³¸ì›ì¸"ì¼ ê²½ìš° â†’ "ì—†ìŒ"ìœ¼ë¡œ ì¹˜í™˜
            if pred_class_name == "ê·¼ë³¸ì›ì¸":
                debug_print(f"âš ï¸ ì˜ˆì¸¡ëœ ì‚¬ê³ ìœ í˜•ì´ 'ê·¼ë³¸ì›ì¸' â†’ 'ì—†ìŒ'ìœ¼ë¡œ ì¹˜í™˜í•©ë‹ˆë‹¤.")
                pred_class_name = "ì™¸ì  ìš”ì¸"
            
            debug_print(f"ğŸ¯ [ìƒ˜í”Œ {idx}] ì˜ˆì¸¡ ê²°ê³¼: {pred_class_name} (index={pred_class_idx})")

            rail_type = input_dict.get("ì² ë„êµ¬ë¶„", "").strip()
            line = input_dict.get("ë…¸ì„ ", "").strip()
            key = (str(rail_type), str(pred_class_name), str(line))
            damage = damage_lookup.get(key, 0)
            damage_risk = damage_to_risk(damage)
            class_risk = class_risk_weights.get(pred_class_name, 0)
            combined_risk = round(0.6 * damage_risk + 0.4 * class_risk, 2)

            debug_print(f"ğŸ§® [ìƒ˜í”Œ {idx}] í”¼í•´ì•¡: {damage}, í”¼í•´ìœ„í—˜ë„: {damage_risk}, ìœ í˜•ìœ„í—˜ë„: {class_risk}, ë³µí•©ìœ„í—˜ë„: {combined_risk}")

            results.append({
                "predicted_cause": pred_class_name,
                "damage_risk": damage_risk,
                "class_risk": class_risk,
                "combined_risk": combined_risk
            })

        debug_print("âœ… ì „ì²´ ì˜ˆì¸¡ ì™„ë£Œ. ì´ ê²°ê³¼ ìˆ˜:", len(results))
        return jsonify(results)

    except Exception as e:
        debug_print("âŒ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", str(e))
        return jsonify({"error": str(e)}), 500

# ------------ ì„œë²„ ì‹¤í–‰ ------------ #
if __name__ == '__main__':
    debug_print("ğŸš€ Flask ì¶”ë¡  ì„œë²„ ì‹¤í–‰ ì‹œì‘")
    app.run(debug=True)
